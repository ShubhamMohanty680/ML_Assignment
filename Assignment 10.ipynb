{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c30d8f2",
   "metadata": {},
   "source": [
    "# Q.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95744b52",
   "metadata": {},
   "source": [
    "1. Simple Linear Regression\n",
    "- Simple linear regression is a statistical method that examines the relationship between two continuous variables. \n",
    "- It involves one independent variable and one dependent variable, and aims to find a linear relationship between them. \n",
    "- An example of simple linear regression is analyzing the relationship between a person's height and weight.\n",
    "\n",
    "2. Multiple Linear Regression\n",
    "- Multiple linear regression, involves examining the relationship between multiple independent variables and one dependent variable. \n",
    "- It aims to find a linear relationship between the independent variables and the dependent variable. \n",
    "- An example of multiple linear regression is analyzing the relationship between a person's salary and their level of education, years of experience, and age.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f891b17",
   "metadata": {},
   "source": [
    "# Q.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d33c13",
   "metadata": {},
   "source": [
    "The assumptions of linear regression are :\n",
    "\n",
    "1. Linear regression assumes that there is a linear relationship between the independent and dependent variables are normally distributed.\n",
    "2. The variance of the residuals is constant across the range of the independent variable,\n",
    "3. There is no multicollinearity among independent variables. \n",
    "\n",
    "\n",
    "These assumptions can be checked by analyzing residual plots, Q-Q plots, and correlation matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4137c39e",
   "metadata": {},
   "source": [
    "# Q.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb658ed",
   "metadata": {},
   "source": [
    "In a linear regression model, the slope represents the rate of change of the dependent variable with respect to the independent variable, while the intercept represents the value of the dependent variable when the independent variable is zero. \n",
    "         \n",
    "         \n",
    "- For example, in a house prediction model house prices based on square foot area, the slope represents the increase in price per square foot, and the intercept represents the base price of a house with zero square footage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adfb28b",
   "metadata": {},
   "source": [
    "# Q.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2e0449",
   "metadata": {},
   "source": [
    "- Gradient descent is a method used in machine learning to find the best values for the parameters of a model by iteratively adjusting them to minimize the error between predicted and actual outcomes.\n",
    "\n",
    "-  It is used in machine learning to minimize the error or cost function of a model by iteratively updating the model's parameters in the direction of steepest descent. It helps the model learn from data and find optimal parameter values that improve its predictive performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c30291",
   "metadata": {},
   "source": [
    "# Q.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e007ce5f",
   "metadata": {},
   "source": [
    "Multiple linear regression is a statistical method that helps us understand the relationship between multiple independent variables and a dependent variable. Unlike simple linear regression, which only uses one independent variable, multiple linear regression considers several independent variables that can impact the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2073a0",
   "metadata": {},
   "source": [
    "# Q.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bae690",
   "metadata": {},
   "source": [
    "- Multicollinearity is a problem in multiple linear regression where the independent variables are highly correlated with each other. \n",
    "\n",
    "\n",
    "- This can cause issues in accurately estimating the effect of each independent variable on the dependent variable. \n",
    "\n",
    "\n",
    "- To detect and address multicollinearity, one can use correlation matrices and variance inflation factors (VIF) to identify highly correlated variables and remove them by using regularization techniques to reduce their impact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0758db",
   "metadata": {},
   "source": [
    "# Q.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2c076d",
   "metadata": {},
   "source": [
    "- Polynomial regression is a type of regression analysis where the relationship between the independent variable (X) and the dependent variables (Y)  is modeled as an nth degree polynomial function.\n",
    "\n",
    "\n",
    "- It differs from linear regression as it allows for a curved relationship between X and Y, rather than assuming a straight line.\n",
    "\n",
    "- It extends the concept of simple linear regression by introducing polynomial terms, allowing for more complex and nonlinear relationships to be captured."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed29eb66",
   "metadata": {},
   "source": [
    "# Q.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87447c16",
   "metadata": {},
   "source": [
    "#### Advantages:\n",
    "   1. Polynomial regression can capture non-linear relationships between variables that linear regression cannot. \n",
    "   2. Polynomial regression can provide a better fit to the data than linear regression. \n",
    "\n",
    "#### Disadvantages:\n",
    "   1. Polynomial regression can be more complex than linear regression, which can lead to overfitting if the model is not carefully tuned. \n",
    "   2. Polynomial regression can be sensitive to outliers.\n",
    "         \n",
    "#### Situations where polynomial regression is preferred:\n",
    "   1. When there is a non-linear relationship between the dependent variable and independent variable(s).\n",
    "   2. When a higher degree of accuracy is required in the predictions.\n",
    "   3. When there is enough data to fit a complex model without overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
